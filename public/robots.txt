# robots.txt
# This file tells search engines which pages they can and cannot crawl

# Allow all search engines to crawl most content
User-agent: *
Allow: /

# Block email harvesting bots and spam bots
User-agent: *
Disallow: /about
# Note: This won't prevent email scraping from HTML content,
# but helps reduce automated email harvesting from specific pages

# Block known spam bots
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: MJ12bot
Disallow: /

# Sitemap location (optional - you can add this if you create a sitemap)
# Sitemap: https://bryange.com/sitemap.xml

